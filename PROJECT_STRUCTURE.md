# ðŸ“ MindMate Project Structure

## ðŸ“‚ Directory Overview

```
mindmate/
â”œâ”€â”€ ðŸ“ src/                    # Source code
â”‚   â”œâ”€â”€ ðŸ¤– bot.py             # Main bot application (voice âœ…)
â”‚   â”œâ”€â”€ ðŸ—„ï¸ database.py        # PostgreSQL connection & models
â”‚   â””â”€â”€ ðŸ“„ config.py           # Configuration constants
â”œâ”€â”€ ðŸ“‹ requirements.txt          # Python dependencies
â”œâ”€â”€ ðŸ³ Dockerfile              # Container configuration
â”œâ”€â”€ ðŸ“„ Procfile               # Render deployment config
â”œâ”€â”€ ðŸ“„ render.yaml            # Render service settings
â”œâ”€â”€ ðŸ“„ .env.example           # Environment variables template
â”œâ”€â”€ ðŸ“„ .gitignore             # Git ignore patterns
â”œâ”€â”€ ðŸ“š docs/                  # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md      # System design
â”‚   â”œâ”€â”€ POSTGRESQL_INTEGRATION_CHECKLIST.md
â”‚   â””â”€â”€ ðŸ“ voice/             # Voice feature documentation
â”‚       â””â”€â”€ VOICE_IMPLEMENTATION_TODO.md   # Voice implementation checklist
â”œâ”€â”€ ðŸ”¬ research/               # Research findings
â”‚   â”œâ”€â”€ MODEL_RESEARCH_FINDINGS.md
â”‚   â”œâ”€â”€ CHATGPT_RESEARCH_FINDINGS.md
â”‚   â”œâ”€â”€ GEMINI_RESEARCH_FINDINGS.md
â”‚   â””â”€â”€ OPENAI_DIRECT_AUDIO_RESEARCH.md
â”œâ”€â”€ ðŸ“ scripts/               # Utility scripts
â”‚   â”œâ”€â”€ test_voice.py        # Voice testing utilities
â”‚   â””â”€â”€ test_bot.py          # Core bot functionality tests
â”œâ”€â”€ ðŸ“Š logs/                  # Application logs
â””â”€â”€ ðŸ—‚ï¸ .windsurf/           # IDE configuration
```

## ðŸ“ Core Files

### ðŸ¤– `src/bot.py`
**Purpose**: Main bot application with FastAPI + Telegram integration
**Key Features**:
- âœ… **Voice Messages**: Transcribe + respond with voice
- âœ… **Personal Mode**: Therapeutic conversations
- âœ… **Crisis Detection**: Immediate helpline resources
- âœ… **Command Menu**: User-friendly interface
- âœ… **Conversation History**: Persistent memory

**Voice Implementation**:
```python
# Voice processing constants
VOICE_TRANSCRIPTION_MODEL = "whisper-1"
VOICE_TTS_MODEL = "tts-1"

# Voice handler
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    # Download voice â†’ Transcribe with Whisper â†’ Process with GPT â†’ Generate TTS â†’ Send voice
```

### ðŸ—„ï¸ `src/database.py`
**Purpose**: PostgreSQL connection and data models
**Features**:
- User profiles and preferences
- Conversation history storage
- Voice selection persistence
- Graceful fallback to in-memory

### ðŸ“‹ `requirements.txt`
**Key Dependencies**:
```
python-telegram-bot==21.0      # Telegram bot framework
openai>=1.12.0,<2.0.0        # OpenAI API (Whisper + GPT + TTS)
python-dotenv                   # Environment variables
fastapi                         # Web framework
uvicorn[standard]              # ASGI server
aiofiles>=23.0.0,<24.0.0    # Async file operations for voice
asyncpg                        # PostgreSQL driver
pydantic                        # Data validation
```

## ðŸš€ Deployment

### ðŸŒ Render Configuration
- **Platform**: Render.com (free tier)
- **Architecture**: FastAPI + Uvicorn + Webhook mode
- **Database**: PostgreSQL (free tier)
- **Webhook**: `https://mindmate-dev.onrender.com/webhook`

### ðŸ³ Container Support
- **Base**: Python 3.12 slim
- **Process**: Single `python src/bot.py` command
- **Port**: 10000 (Render standard)

## ðŸ“š Documentation

### ðŸ“‹ Core Docs
- **README.md**: Project overview and setup
- **ARCHITECTURE.md**: System design and patterns
- **ROADMAP.md**: Feature planning and timeline

### ðŸ”¬ Research Docs
- **MODEL_RESEARCH_FINDINGS.md**: AI model evaluation and selection
- **OPENAI_DIRECT_AUDIO_RESEARCH.md**: Direct audio-to-audio model research

### ðŸ“ Implementation Docs
- **VOICE_IMPLEMENTATION_TODO.md**: Voice feature implementation checklist â†’ **docs/voice/**
- **VOICE_ERROR_ANALYSIS.md**: Voice debugging and fixes â†’ **docs/voice/**

## ðŸŽ¯ Current Status

### âœ… **Completed Features**
- [x] **Voice Messages**: Full voice-to-voice conversation
- [x] **Personal Mode**: Therapeutic AI conversations
- [x] **Crisis Detection**: Automatic resource provision
- [x] **Command Menu**: Enhanced UX with emoji labels
- [x] **Conversation History**: PostgreSQL + in-memory fallback

### ðŸš§ **Current Limitations**
- [ ] **Voice Selection**: Currently only female voice (alloy)
- [ ] **Voice Controls**: No speed/pitch/emotion adjustments
- [ ] **Multi-language**: English only

### ðŸŽ›ï¸ **Next: Voice Selection**
**Priority**: P2 (Medium)
**Timeline**: 1 week
**Goal**: Allow users to choose voice personality

**Available Voices**:
- âš–ï¸ **alloy** (current) - Balanced, neutral
- ðŸ‘¨ **echo** - Male, confident
- ðŸ‘© **fable** - Warm, caring
- ðŸŽ­ **onyx** - Deep, thoughtful
- ðŸŒŸ **nova** - Friendly, upbeat
- âœ¨ **shimmer** - Gentle, soft

---

**Last Updated**: 2026-02-07  
**Version**: v1.2 (Voice Support Complete)
